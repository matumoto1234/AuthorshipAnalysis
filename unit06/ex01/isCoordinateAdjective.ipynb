{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70KiMGWJJebs",
        "outputId": "c25a0fc2-b22f-42f2-ae78-3c8008077384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TrxWJhhJnDn",
        "outputId": "5d332a7e-a405-47bd-b035-ccfeeeb227dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all test case size : 11\n",
            "classification accuracy : 72.72727272727273 %\n"
          ]
        }
      ],
      "source": [
        "from enum import Enum\n",
        "import nltk\n",
        "\n",
        "def count_coordinate_adjectives(sentence: list[str]) -> int:\n",
        "    tokens: list[str] = nltk.word_tokenize(sentence)\n",
        "    tagged: list[tuple[str, str]] = nltk.pos_tag(tokens)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(tagged) - 2):\n",
        "        tag = tagged[i][1]\n",
        "        next_token = tagged[i + 1][0]\n",
        "        after_next_tag = tagged[i + 2][1]\n",
        "\n",
        "        if tag == \"JJ\" and next_token == \",\" and after_next_tag == \"JJ\":\n",
        "            count += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "def count_non_coordinate_adjectives(sentence: list[str]) -> int:\n",
        "    tokens: list[str] = nltk.word_tokenize(sentence)\n",
        "    tagged: list[tuple[str, str]] = nltk.pos_tag(tokens)\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(tagged) - 1):\n",
        "        tag = tagged[i][1]\n",
        "        next_tag = tagged[i + 1][1]\n",
        "\n",
        "        if tag == \"JJ\" and next_tag == \"JJ\":\n",
        "            count += 1\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "def is_coordinate(sentence: str) -> bool:\n",
        "    return count_coordinate_adjectives(sentence) > count_non_coordinate_adjectives(sentence)\n",
        "\n",
        "\n",
        "class AdjectiveCategory(Enum):\n",
        "    COORDINATE = 1\n",
        "    NON_COORDINATE = 2\n",
        "\n",
        "\n",
        "def classify_adjective(sentence: str) -> AdjectiveCategory:\n",
        "    if is_coordinate(sentence):\n",
        "        return AdjectiveCategory.COORDINATE\n",
        "\n",
        "    return AdjectiveCategory.NON_COORDINATE\n",
        "\n",
        "\n",
        "def main():\n",
        "    coordinate_sentences: list[str] = [\n",
        "        \"Forecasters warned of another day of hot, windy conditions across Southern California on Sunday.\",\n",
        "        \"n addition, their breathtakingly cruel, callous actions also led to a tribute plaque.\",\n",
        "        \"Obama stands accused of giving stuffy, cliche-ridden graduation speeches.\",\n",
        "        \"The company is also working on a new, cheaper iPhone.\",\n",
        "        \"I have a new, expensive car.\",\n",
        "        \"The girl is beautiful, smart, and funny.\",\n",
        "    ]\n",
        "\n",
        "    non_coordinate_sentences: list[str] = [\n",
        "        \"Amazon prepping multiple wallet-friendly tablets.\",\n",
        "        \"With this in mind, I wanted to design a screen to identify dirt-cheap smaller companies.\",\n",
        "        \"The Red Wings are demonstrably a tough hockey team.\",\n",
        "        \"I saw a happy little kid in the park.\",\n",
        "        \"We ate a delicious deer meat.\"\n",
        "        \"My friend buys a expensive red car.\"\n",
        "    ]\n",
        "\n",
        "    correct = 0\n",
        "    for sentence in coordinate_sentences:\n",
        "        if classify_adjective(sentence) == AdjectiveCategory.COORDINATE:\n",
        "            correct += 1\n",
        "\n",
        "    for sentence in non_coordinate_sentences:\n",
        "        if classify_adjective(sentence) == AdjectiveCategory.NON_COORDINATE:\n",
        "            correct += 1\n",
        "\n",
        "    all_size = len(coordinate_sentences) + len(non_coordinate_sentences)\n",
        "    print(\"all test case size :\", all_size)\n",
        "    print(\"classification accuracy :\", correct / all_size * 100, \"%\")\n",
        "\n",
        "\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}